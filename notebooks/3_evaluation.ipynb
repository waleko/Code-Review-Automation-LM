{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc60e7255799cccf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Predictions Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.smooth_bleu import bleu_fromstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e1f5dc15fd5625",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_preds(base_file, sample_size=5):\n",
    "    # read files\n",
    "    hf_preds_file = Path(base_file).with_suffix('.hf_pred.csv')\n",
    "    fine_tuned_file = Path(base_file).with_suffix('.finetuned_pred.csv')\n",
    "    hf_preds = pd.read_csv(hf_preds_file)\n",
    "    fine_tuned = pd.read_csv(fine_tuned_file)\n",
    "    # put in df\n",
    "    df = pd.DataFrame({'code': fine_tuned['code'],\n",
    "     'hf_pred': hf_preds['prediction'],\n",
    "     'fine_tuned_pred': fine_tuned['prediction'],\n",
    "     'target': fine_tuned['target']})\n",
    "    df.replace(np.nan, '', regex=True)\n",
    "    # print sample with predictions\n",
    "    sample = df.sample(sample_size, random_state=42)\n",
    "    for code, hf_pred, fine_tuned_pred, target in sample.to_numpy():\n",
    "        print('-------------------')\n",
    "        print(code)\n",
    "        print(f'## Human Review: {target}')\n",
    "        print(f'## HF Pred: {hf_pred}')\n",
    "        print(f'## Fine Tuned Pred: {fine_tuned_pred}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5e6defa2df6726",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_bleu(df):\n",
    "    refs = list(df['target'])\n",
    "    preds = list(df['prediction'])\n",
    "    for i in range(len(preds)):\n",
    "        chars = \"(_)`.\"\n",
    "        for c in chars:\n",
    "            preds[i] = preds[i].replace(c, \" \" + c + \" \")\n",
    "            preds[i] = \" \".join(preds[i].split())\n",
    "            refs[i] = refs[i].replace(c, \" \" + c + \" \")\n",
    "            refs[i] = \" \".join(refs[i].split())\n",
    "    return bleu_fromstr(preds, refs, rmstop=False)\n",
    "\n",
    "def calc_bleu_score(base_file):\n",
    "    hf_preds_file = Path(base_file).with_suffix('.hf_pred.csv')\n",
    "    fine_tuned_file = Path(base_file).with_suffix('.finetuned_pred.csv')\n",
    "    hf_preds = pd.read_csv(hf_preds_file)\n",
    "    ft_preds = pd.read_csv(fine_tuned_file)\n",
    "    hf_preds.replace(np.nan, '', regex=True, inplace=True)\n",
    "    ft_preds.replace(np.nan, '', regex=True, inplace=True)\n",
    "    hf_bleu = calc_bleu(hf_preds)\n",
    "    ft_bleu = calc_bleu(ft_preds)\n",
    "    print(f'HF BLEU: {hf_bleu}')\n",
    "    print(f'Fine Tuned BLEU: {ft_bleu}')\n",
    "    return hf_bleu, ft_bleu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3698532ffeff76b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Qualitative Evaluation\n",
    "We will now compare the predictions of the HF model and the fine-tuned model on samples of the four datasets.\n",
    "\n",
    "We will print the code, the prediction of the HF model and the prediction of the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642eedcac45ee834",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30dc56606146a2d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "@@ -1,6 +1,7 @@\n",
      " # frozen_string_literal: true\n",
      "\n",
      " require 'hocon'\n",
      "+require 'bolt/error'\n",
      "\n",
      " class TransportConfig\n",
      "   attr_accessor :host, :port, :ssl_cert, :ssl_key, :ssl_ca_cert, :ssl_cipher_suites,\n",
      "## Human Review: Looks like this isn't used in this file?\n",
      "## HF Pred: Why do we need this?\n",
      "## Fine Tuned Pred: I am surprised you don't use `hocon` here.\n",
      "-------------------\n",
      "@@ -92,7 +92,7 @@ public final class OAuth2AuthorizedClientArgumentResolver implements HandlerMeth\n",
      " \t\t\t\t\t\t\tclientRegistrationId.flatMap(id -> Mono.error(new IllegalStateException(\n",
      " \t\t\t\t\t\t\t\t\t\"Unable to resolve the Authorized Client with registration identifier \\\"\"\n",
      " \t\t\t\t\t\t\t\t\t\t\t+ id\n",
      "-\t\t\t\t\t\t\t\t\t\t\t+ \"\\\". An \\\"authenticated\\\" or \\\"unauthenticated\\\" session is required. To allow for unauthenticated access, ensure ServerHttpSecurity.anonymous() is configured.\"))))\n",
      "+\t\t\t\t\t\t\t\t\t\t\t+ \"\\\". An \\\"authenticated\\\" or \\\"anonymous\\\" request is required. To allow for anonymous access, ensure ServerHttpSecurity.anonymous() is configured.\"))))\n",
      " \t\t\t\t\t.flatMap(zipped -> {\n",
      " \t\t\t\t\t\tString registrationId = zipped.getT1();\n",
      " \t\t\t\t\t\tString username = zipped.getT2();\n",
      "## Human Review: I don't think this should be changed since on the reactive side we don't support anonymous users.\n",
      "## HF Pred: I don't think we should change this message. It's not clear to me why this is an error.\n",
      "## Fine Tuned Pred: I think this message should be updated. `An \"anonymous\" request is required. To allow for anonymous access, ServerHttpSecurity.anonymous() is configured.`\n",
      "-------------------\n",
      "@@ -3,7 +3,7 @@ const test = require('./shared').assert,\n",
      "   setupDatabase = require('./shared').setupDatabase,\n",
      "   Script = require('vm'),\n",
      "   expect = require('chai').expect,\n",
      "-  normalizedFunctionString = require('bson/lib/bson/parser/utils').normalizedFunctionString,\n",
      "+  normalizedFunctionString = require('bson/lib/parser/utils').normalizedFunctionString,\n",
      "   Buffer = require('safe-buffer').Buffer;\n",
      "\n",
      " const {\n",
      "## Human Review: feel free when editing sections like this to introduce modern features like object destructuring.\n",
      "## HF Pred: Why this change?\n",
      "## Fine Tuned Pred: whats with the whitespace changes in this file?\n",
      "-------------------\n",
      "@@ -0,0 +1,17 @@\n",
      "+<?php\n",
      "+/**\n",
      "+ * Copyright Â© Bold Brand Commerce Sp. z o.o. All rights reserved.\n",
      "+ * See LICENSE.txt for license details.\n",
      "+ */\n",
      "+\n",
      "+declare(strict_types=1);\n",
      "+\n",
      "+namespace Ergonode\\Core\\Infrastructure\\Exception;\n",
      "+\n",
      "+class SerializationException extends SerializerException\n",
      "+{\n",
      "+    public function __construct(string $message, \\Throwable $previous = null)\n",
      "+    {\n",
      "+        parent::__construct($message, $previous);\n",
      "+    }\n",
      "+}\n",
      "## Human Review: I think it should been in `SharedKernel` module.\n",
      "## HF Pred: Missing license header.\n",
      "## Fine Tuned Pred: Why do we need a separate exception class here? Seems very specific to Elgg\\Core\\Infrastructure\\Exception\n",
      "-------------------\n",
      "@@ -473,6 +473,7 @@ describe('GridFS Stream', function () {\n",
      "                     // Fail if user tries to abort an aborted stream\n",
      "                     uploadStream.abort().then(null, function (error) {\n",
      "                       expect(error.toString()).to.equal(\n",
      "+                        // TODO(NODE-3405): Replace with MongoStreamClosedError\n",
      "                         'MongoDriverError: Cannot call abort() on a stream twice'\n",
      "                       );\n",
      "                       client.close(done);\n",
      "## Human Review: You can remove these if they've been resolved in NODE-3405 and this isn't depending on it\n",
      "## HF Pred: Is this TODO still relevant?\n",
      "## Fine Tuned Pred: What is the problem here?\n"
     ]
    }
   ],
   "source": [
    "df['msg'] = analyze_preds('../data/msg-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19fbf302695a4c36",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "@@ -340,6 +341,17 @@ export class DebugEditorContribution implements IDebugEditorContribution {\n",
      " \t\treturn new RunOnceScheduler(() => this.hoverWidget.hide(), HOVER_DELAY);\n",
      " \t}\n",
      " \n",
      "+\t@memoize\n",
      "+\tprivate get provideNonDebugHoverScheduler(): RunOnceScheduler {\n",
      "+\t\treturn new RunOnceScheduler(() => {\n",
      "## Human Review: Where is this disposed?\n",
      "## HF Pred: Why is this memoized?\n",
      "## Fine Tuned Pred: This is not `Runnable` but `RunOnceScheduler`, right?\n",
      "-------------------\n",
      "@@ -53,6 +53,11 @@ export class SassParser extends cssParser.Parser {\n",
      " \n",
      " \t// Sass variables: $font-size: 12px;\n",
      " \tpublic _parseVariableDeclaration(panic:scanner.TokenType[]=[]): nodes.VariableDeclaration {\n",
      "+\t\tvar cssVariableDeclaration= super._parseCssVariableDeclaration(panic);\n",
      "## Human Review: That looks wrong. Not all places where you can declare a sass variable are also suited to declare a css variable.\n",
      "\n",
      "## HF Pred: Nit: space after `=`\n",
      "## Fine Tuned Pred: Minor style issue: missing space before the `=`\n",
      "-------------------\n",
      "@@ -537,6 +537,23 @@ export interface CompletionList {\n",
      " \t */\n",
      " \titems: CompletionItem[];\n",
      " }\n",
      "+\n",
      "+/**\n",
      "+ * Contains additional information about the context in which\n",
      "+ * [completion provider](#CompletionItemProvider.provideCompletionItems) is triggered.\n",
      "+ */\n",
      "+export interface CompletionContext {\n",
      "## Human Review: This also needs the following information  *manual* invocation, *24x7* IntelliSense, completing incomplete result set \n",
      "## HF Pred: I don't think we need this interface. We can just use `CompletionItemProvider`.\n",
      "## Fine Tuned Pred: Is there a reason this is not an object?\n",
      "-------------------\n",
      "@@ -439,6 +441,16 @@ export class DebugService implements debug.IDebugService {\n",
      " \t\t});\n",
      " \t}\n",
      " \n",
      "+\tprivate debouncedDisplayThreads(session: RawDebugSession) {\n",
      "+\t\tconst timer = this.displayThreadsTimer.get(session.getId());\n",
      "+\t\tif (timer) {\n",
      "+\t\t\tclearTimeout(timer);\n",
      "+\t\t}\n",
      "+\t\tthis.displayThreadsTimer.set(session.getId(), setTimeout(() => {\n",
      "+\t\t\tthis.fetchThreads(session).done(undefined, errors.onUnexpectedError);\n",
      "## Human Review: This will make \n",
      "## HF Pred: I'm not sure if this is the best way to do this. I think it would be better to do this in the `fetchThreads` function.\n",
      "## Fine Tuned Pred: Is there a reason we can't just use `clearTimeout` here? Is there any difference in the code between `clearTimeout` and `set`?\n",
      "-------------------\n",
      "@@ -265,4 +266,33 @@ class MDDocumentContentProvider implements TextDocumentContentProvider {\n",
      " \t\t\t}, 300);\n",
      " \t\t}\n",
      " \t}\n",
      "+}\n",
      "+\n",
      "+class DocumentHeadingsProvider implements vscode.DocumentSymbolProvider {\n",
      "+\n",
      "+\t// http://daringfireball.net/projects/markdown/syntax#header\n",
      "+\tprivate static _atxPattern = /^(#){1,6}\\s+.+(\\s+\\1)?/;\n",
      "+\tprivate static _settext = /^\\s*[-=]+\\s*$/;\n",
      "## Human Review: Make sure to also test that this does not pick up separators\n",
      "\n",
      "## HF Pred: nit: `_atxPattern` -> `_atxRegex`\n",
      "## Fine Tuned Pred: Remove this and use directly the `SymbolProvider` below.\n"
     ]
    }
   ],
   "source": [
    "df['vscode'] = analyze_preds('../data/microsoft_vscode_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f7b55edbe73e06",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "@@ -24,10 +24,13 @@ abstract class AbstractIrLineNumberTest : AbstractLineNumberTest() {\n",
      " \n",
      "     override fun compareCustom(psiFile: KtFile, wholeFile: File) {\n",
      "         val fileText = psiFile.text\n",
      "-        val expectedLineNumbers = normalize(\n",
      "-            fileText.substring(fileText.indexOf(\"//\") + 2)\n",
      "-                .trim().split(\" \").map { it.trim() }.toMutableList()\n",
      "-        )\n",
      "+        val expectedLineNumbers = fileText.split(\"\\n\".toRegex()).filter { line ->\n",
      "## Human Review: How about simplifying this to:\n",
      "\n",
      "        val expectedLineNumbers = normalize(\n",
      "            fileText.substring(Regex(\"// \\\\d+\").find(fileText)!!.range.start + 2)\n",
      "                .trim().split(\" \").map { it.trim() }.toMutableList()\n",
      "        )\n",
      "\n",
      "Then we are looking for a line that starts with \"// \" with a number of digits after it. That should work to exclude the comment lines with text. That looks consistent with what the old backend expects from these tests.\n",
      "## HF Pred: Why did you change this?\n",
      "## Fine Tuned Pred: Remove the `toRegex()` call here.\n",
      "-------------------\n",
      "@@ -45,7 +45,6 @@ import org.jetbrains.kotlin.types.KotlinType\n",
      " import org.jetbrains.kotlin.types.typeUtil.isPrimitiveNumberType\n",
      " import org.jetbrains.kotlin.types.typeUtil.makeNotNullable\n",
      " import org.jetbrains.kotlin.types.typeUtil.makeNullable\n",
      "-import java.lang.AssertionError\n",
      "## Human Review: Pls remove this file from pr\n",
      "## HF Pred: import org.jetbrains.kotlin.util.KotlinConstants;\n",
      "## Fine Tuned Pred: Why did you remove this import?\n",
      "-------------------\n",
      "@@ -46,6 +46,7 @@ abstract class AbstractCheckLocalVariablesTableTest : CodegenTestCase() {\n",
      "             assertNotNull(\"Couldn't find class file for pattern $classFileRegex in: $pathsString\", outputFile)\n",
      " \n",
      "             val actualLocalVariables = readLocalVariable(ClassReader(outputFile.asByteArray()), methodName)\n",
      "+            checkLocalVariableTypes(ClassReader(outputFile.asByteArray()), methodName, actualLocalVariables)\n",
      "## Human Review: Could we reuse class reader from previous line?\n",
      "## HF Pred: assertEquals(expectedLocalVariables, actualLocalVariables)\n",
      "## Fine Tuned Pred: What's the purpose of this line?\n",
      "-------------------\n",
      "@@ -37,3 +37,17 @@ public fun Char.equals(other: Char, ignoreCase: Boolean = false): Boolean {\n",
      "  * Returns `true` if this character is a Unicode surrogate code unit.\n",
      "  */\n",
      " public fun Char.isSurrogate(): Boolean = this in Char.MIN_SURROGATE..Char.MAX_SURROGATE\n",
      "+\n",
      "+/**\n",
      "+ * Minimum value for character\n",
      "+ * @see <a href=\"https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html\">\n",
      "## Human Review: I don't think this way of linking is supported in `@see` tag.  I'm not sure what is the purpose of these links anyway.\n",
      "## HF Pred: This should be `Char.isSurrogate()`.\n",
      "## Fine Tuned Pred: Please remove the `<a>` tag.\n",
      "-------------------\n",
      "@@ -175,7 +195,9 @@ class ExpressionCodegen(\n",
      " \n",
      "     override fun visitBlockBody(body: IrBlockBody, data: BlockInfo): StackValue {\n",
      "         return body.statements.fold(none()) { _, exp ->\n",
      "-            exp.accept(this, data)\n",
      "+            val result = exp.accept(this, data)\n",
      "+            (exp as? IrExpression)?.markEndOfStatementIfNeeded()\n",
      "## Human Review: ```\n",
      "exp.accept(this, data).also {\n",
      "       (exp as? IrExpression)?.markEndOfStatementIfNeeded()\n",
      "}\n",
      "```\n",
      "## HF Pred: Why is this needed?\n",
      "## Fine Tuned Pred: Unrelated to this PR, but this doesn't seem like the best place to markEndOfStatementIfNeeded. Should the markEndOfStatementIfNeeded be in some other place, or should the markEndOfStatementIfNeeded be in BlockInfoResolver?\n"
     ]
    }
   ],
   "source": [
    "df['kotlin'] = analyze_preds('../data/JetBrains_kotlin_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a70e469063ec64",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "@@ -28,6 +28,7 @@\n",
      "     \"@uppy/thumbnail-generator\": \"0.29.1\",\n",
      "     \"@uppy/utils\": \"0.29.1\",\n",
      "     \"classnames\": \"^2.2.6\",\n",
      "+    \"cuid\": \"^2.1.1\",\n",
      "     \"drag-drop\": \"2.13.3\",\n",
      "## Human Review: In other places we are using uuid, I think, is there a reason to use different packages? I was actually gonna suggest we switch to https://github.com/ai/nanoid everywhere, itâs smaller and ids are smaller.\n",
      "## HF Pred: This should be `^2.1.0`, right?\n",
      "## Fine Tuned Pred: Why are we using a fixed version here?\n",
      "-------------------\n",
      "@@ -49,7 +49,8 @@ class Tabs extends Component {\n",
      "             tabindex=\"-1\"\n",
      "             type=\"file\"\n",
      "             name=\"files[]\"\n",
      "-            multiple=\"true\"\n",
      "+            multiple={this.props.maxNumberOfFiles !== 1 || !this.props.maxNumberOfFiles}\n",
      "## Human Review: same here\n",
      "## HF Pred: `multiple={this.props.maxNumberOfFiles !== 1}`\n",
      "## Fine Tuned Pred: shouldnt it be only true if `this.props.maxNumberOfFiles` is defined ?\n",
      "-------------------\n",
      "@@ -496,6 +494,25 @@ module.exports = class ProviderView {\n",
      "     }\n",
      "   }\n",
      " \n",
      "+  listAllFiles (path, files = null) {\n",
      "+    files = files || []\n",
      "+    return new Promise((resolve) => {\n",
      "+      this.provider.list(path).then((res) => {\n",
      "## Human Review: should we add a `catch` for this call. Otherwise what will happen when the call to `this.provider.list` fails?\n",
      "## HF Pred: `files = files || []`\n",
      "## Fine Tuned Pred: `resolve` is unnecessary here, you can just call `this.provider.list(path, files)`\n",
      "-------------------\n",
      "@@ -422,7 +422,7 @@ module.exports = class ProviderView {\n",
      "   }\n",
      " \n",
      "   handleAuth () {\n",
      "-    const authState = btoa(JSON.stringify({ origin: location.origin }))\n",
      "+    const authState = btoa(JSON.stringify({ origin: location.origin, redirect: 'http://localhost:3' }))\n",
      "     const link = `${this.provider.authUrl()}?state=${authState}`\n",
      "## Human Review: `http://localhost:3` ð¤ \n",
      "## HF Pred: I think this should be `https://localhost:3`\n",
      "## Fine Tuned Pred: I think it would be better if we could use `location.protocol` here instead of hardcoding `localhost:3`\n",
      "-------------------\n",
      "@@ -2,6 +2,14 @@\n",
      " \n",
      " echo \"Preparing for end to end test: copying static HTML and CSS, building JS\"\n",
      " rm -rf ./test/endtoend/dist && mkdir ./test/endtoend/dist\n",
      "-cp ./dist/uppy.min.css ./test/endtoend/dist \n",
      "-cp ./test/endtoend/src/index.html ./test/endtoend/dist \n",
      "+rm -rf ./test/endtoend/node_modules\n",
      "+\n",
      "+UPPY_VERSION=$(cat package.json | grep version | head -1 | awk -F= \"{ print $2 }\" | sed 's/[version:,\\\",]//g' | tr -d '[[:space:]]')\n",
      "+# archive the uppy package\n",
      "+npm pack\n",
      "## Human Review: I think we should also run the `npm run prepublishOnly` script first here, so that the package is exactly the same as the published one (I thought this would happen automatically inside `npm pack` but it doesn't seem to)\n",
      "## HF Pred: Why do we need this?\n",
      "## Fine Tuned Pred: Do we want to keep the old version or is there a way to upgrade to a newer version?\n"
     ]
    }
   ],
   "source": [
    "df['uppy'] = analyze_preds('../data/transloadit_uppy_1000.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88786c13e63fb984",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see, the models are pretty mediocre at understanding the issue. But I find that the HF model tends to produce more generic predictions, while the fine-tuned model produces predictions that are more specific to the code and shows a better understanding.\n",
    "\n",
    "Still, both models predict something sensible but struggle to pin-point the problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c86e2ae168dbf9a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Quantitative Evaluation\n",
    "For each dataset, we calculate the [BLEU-4](https://en.wikipedia.org/wiki/BLEU) score for the predictions of the HF model and the fine-tuned model. The BLEU score is a measure of how similar the predictions are to the target. The higher the score, the better the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860cd835ad7fc0c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 10169\n",
      "Total: 10169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF BLEU: 5.14\n",
      "Fine Tuned BLEU: 5.34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.14, 5.34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu_score('../data/msg-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf7bf5989d87648",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 1000\n",
      "Total: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF BLEU: 3.39\n",
      "Fine Tuned BLEU: 4.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.39, 4.02)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu_score('../data/microsoft_vscode_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3bea9368dc3041",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF BLEU: 3.39\n",
      "Fine Tuned BLEU: 4.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.39, 4.32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu_score('../data/JetBrains_kotlin_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2ed67a1d9adcf63",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF BLEU: 4.55\n",
      "Fine Tuned BLEU: 4.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.55, 4.84)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bleu_score('../data/transloadit_uppy_1000.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b14a888443bebefe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see, the fine-tuned model performs slightly better than the HF model on all datasets.\n",
    "\n",
    "Nevertheless, the score is still pretty low (as the authors of {cite}`li2022codereviewer` put it: \"it is a hard task\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
